{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/Redislabs-Solution-Architects/Redis-Workshops/blob/main/05-LangChain_Redis/05.1_OpenAI_LangChain_Redis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2-i8jBl9GRH"
   },
   "source": [
    "# Document Question Answering with LangChain, OpenAI and Redis\n",
    "\n",
    "![Redis](https://redis.com/wp-content/themes/wpx/assets/images/logo-redis.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "This notebook would use OpenAI, Redis with Vector Similarity Search and LangChain to answer questions about the information contained in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZsd9twK9-sJ"
   },
   "source": [
    "### Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8uONNrVbe08",
    "outputId": "883b2ae1-d471-4c4a-e37a-7d286edd6d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q redis langchain tiktoken openai \"unstructured[all-docs]\" pdf2image pdfminer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Initialize OpenAI\n",
    "\n",
    "You need to supply the OpenAI API key (starts with `sk-...`) when prompted. You can find your API key at https://platform.openai.com/account/api-keys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxPIg3nZyNp9",
    "outputId": "e0bd8afc-5244-4005-9914-3632ae76f108"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "if OPENAI_API_KEY == \"\":\n",
    "    key=getpass.getpass(prompt='OpenAI Key: ', stream=None)\n",
    "    os.environ['OPENAI_API_KEY']=key\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBlbUrB27QQs"
   },
   "source": [
    "### Install Redis Stack (OPTIONAL)\n",
    "\n",
    "Redis Search will be used as Vector Similarity Search engine for LangChain.\n",
    "\n",
    "Instead of using in-notebook Redis Stack https://redis.io/docs/getting-started/install-stack/ you can provision your own free instance of Redis in the cloud. Get your own Free Redis Cloud instance at https://redis.com/try-free/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKMKXPY2j8Gt",
    "outputId": "c91defdc-c530-415a-ae4d-381ba68e909c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb focal main\n",
      "Starting redis-stack-server, database path /var/lib/redis-stack\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "sudo apt-get update  > /dev/null 2>&1\n",
    "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
    "redis-stack-server --daemonize yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7UsU1Ts7TUL"
   },
   "source": [
    "### Connect to Redis\n",
    "\n",
    "By default this notebook would connect to the local instance of Redis Stack. If you have your own Redis Cloud instance - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dyPfCO3pkB7M"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import os\n",
    "\n",
    "\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")\n",
    "#Replace values above with your own if using Redis Cloud instance\n",
    "#REDIS_HOST=\"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
    "#REDIS_PORT=18374\n",
    "#REDIS_PASSWORD=\"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
    "\n",
    "#shortcut for redis-cli $REDIS_CONN command\n",
    "if REDIS_PASSWORD!=\"\":\n",
    "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT} -a {REDIS_PASSWORD} --no-auth-warning\"\n",
    "else:\n",
    "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT}\"\n",
    "\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\"\n",
    "INDEX_NAME = f\"qna:idx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_h1e-L9yZfaY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.redis import Redis\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXDbABtw-vAQ"
   },
   "source": [
    "### Load text and split it into manageable chunks\n",
    "\n",
    "Without this step any large body of text would exceed the limit of tokens you can feed to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zfOlQeeZjsN",
    "outputId": "e5d766f4-04e3-4683-bf18-1201fec84f39"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'open_filename' from 'pdfminer.utils' (/Users/eric.preston/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/pdfminer/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 7\u001B[0m\n\u001B[1;32m      2\u001B[0m docs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/resources/aapl-10k-2023.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/resources/amzn-10k-2023.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      5\u001B[0m ]\n\u001B[1;32m      6\u001B[0m loader \u001B[38;5;241m=\u001B[39m UnstructuredFileLoader(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresources/aapl-10k-2023.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melements\u001B[39m\u001B[38;5;124m\"\u001B[39m, strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfast\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m documents \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m text_splitter \u001B[38;5;241m=\u001B[39m RecursiveCharacterTextSplitter(chunk_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, chunk_overlap\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, add_start_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      9\u001B[0m texts \u001B[38;5;241m=\u001B[39m text_splitter\u001B[38;5;241m.\u001B[39msplit_documents(documents)\n",
      "File \u001B[0;32m~/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/langchain/document_loaders/unstructured.py:71\u001B[0m, in \u001B[0;36mUnstructuredBaseLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[Document]:\n\u001B[1;32m     70\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load file.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m     elements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_elements\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melements\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     73\u001B[0m         docs: List[Document] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n",
      "File \u001B[0;32m~/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/langchain/document_loaders/unstructured.py:154\u001B[0m, in \u001B[0;36mUnstructuredFileLoader._get_elements\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_elements\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpartition\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m partition\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m partition(filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munstructured_kwargs)\n",
      "File \u001B[0;32m~/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/unstructured/partition/auto.py:80\u001B[0m\n\u001B[1;32m     78\u001B[0m pdf_imports \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpdf2image\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpdfminer\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPIL\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(dependency_exists(dep) \u001B[38;5;28;01mfor\u001B[39;00m dep \u001B[38;5;129;01min\u001B[39;00m pdf_imports):\n\u001B[0;32m---> 80\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpartition\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpdf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m partition_pdf\n\u001B[1;32m     82\u001B[0m     PARTITION_WITH_EXTRAS_MAP[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpdf\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m partition_pdf\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dependency_exists(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munstructured_inference\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/unstructured/partition/pdf.py:24\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpdfminer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpdfpage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PDFPage\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpdfminer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpdftypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PDFObjRef\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpdfminer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m open_filename\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchunking\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtitle\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_chunking_strategy\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munstructured\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcleaners\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     28\u001B[0m     clean_extra_whitespace_with_index_run,\n\u001B[1;32m     29\u001B[0m     index_adjustment_after_clean_extra_whitespace,\n\u001B[1;32m     30\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'open_filename' from 'pdfminer.utils' (/Users/eric.preston/work/redis-SA/financial-vss/venv/lib/python3.11/site-packages/pdfminer/utils.py)"
     ]
    }
   ],
   "source": [
    "# Add your own URLs here\n",
    "docs = [\n",
    "    \"/resources/aapl-10k-2023.pdf\",\n",
    "    \"/resources/amzn-10k-2023.pdf\"\n",
    "]\n",
    "loader = UnstructuredFileLoader(\"resources/aapl-10k-2023.pdf\", mode=\"elements\", strategy=\"fast\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index = True)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "# Optionally examine the result of text load+splitting\n",
    "for text in texts:\n",
    "  print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv1JVm31_OF9"
   },
   "source": [
    "### Initialize embeddings engine\n",
    "\n",
    "Using OpenAI Embeddings API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gaJrhuKa_Mwt"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zgvqB6wCJWK"
   },
   "source": [
    "### Initialize LLM\n",
    "\n",
    "In this notebook we are using OpenAI Chat GPT LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iQRyyWU0CNbJ"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qrj-jeGmBRTL"
   },
   "source": [
    "### Create vector store from the documents using Redis as Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yY69FViAjNv1"
   },
   "outputs": [],
   "source": [
    "def get_vectorstore() -> Redis:\n",
    "    \"\"\"Create the Redis vectorstore.\"\"\"\n",
    "\n",
    "    try:\n",
    "        vectorstore = Redis.from_existing_index(\n",
    "            embedding=embeddings,\n",
    "            index_name=INDEX_NAME,\n",
    "            redis_url=REDIS_URL\n",
    "        )\n",
    "        return vectorstore\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Load Redis with documents\n",
    "    vectorstore = Redis.from_documents(\n",
    "        documents=texts,\n",
    "        embedding=embeddings,\n",
    "        index_name=INDEX_NAME,\n",
    "        redis_url=REDIS_URL\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "redis = get_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdzQa112Bf2b"
   },
   "source": [
    "## Specify the prompt template\n",
    "\n",
    "PromptTemplate defines the exect text of the response that would be fed to the LLM. This step is optional, but the defaults usually work well for OpenAI and might fall short for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yKKn2KKp3TQ4"
   },
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"Create the QA chain.\"\"\"\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "\n",
    "    # Define our prompt\n",
    "    prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    This should be in the following format:\n",
    "\n",
    "    Question: [question here]\n",
    "    Answer: [answer here]\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Context:\n",
    "    ---------\n",
    "    {context}\n",
    "    ---------\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgEXBujxG1dO"
   },
   "source": [
    "### Putting it all together\n",
    "\n",
    "This is where the Langchain brings all the components together in a form of a simple QnA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RKNSP0zqZq98"
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=redis.as_retriever(),\n",
    "    #return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    #verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ox7LffJ8VNe"
   },
   "source": [
    "### Debugging Redis\n",
    "\n",
    "The code block below is example of how you can interact with the Redis Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rGH8mdG2na0w"
   },
   "outputs": [],
   "source": [
    "#!redis-cli $REDIS_CONN keys \"*\"\n",
    "#!redis-cli $REDIS_CONN HGETALL \"doc:qna:idx:063955c855a7436fbf9829821332ed2a\"\n",
    "\n",
    "###-- FLUSHDB will wipe out the entire database!!! Use with caution --###\n",
    "#!redis-cli $REDIS_CONN flushdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SURTtVbYBFGc"
   },
   "source": [
    "## Finally - let's ask questions!\n",
    "\n",
    "Examples:\n",
    "- What did the president say about Kentaji Brown Jackson\n",
    "- Did he mention Stephen Breyer?\n",
    "- What was his stance on Ukraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "0JkswfOHZu9h",
    "outputId": "9bc0b5d4-6281-4cc0-ae31-1d97c4186f4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" The president said that Judge Ketanji Brown Jackson is one of the nation's top legal minds and a consensus builder who has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Kentaji Brown Jackson?\"\n",
    "res=qa(query)\n",
    "res['result']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
